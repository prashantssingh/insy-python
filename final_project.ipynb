{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final_project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARz3MeSksONa"
      },
      "source": [
        "# imports \n",
        "import requests\n",
        "import csv\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zU8IWDDKklH"
      },
      "source": [
        "# This function takes the parsed-html page and process the tags to extract the stocks\n",
        "# From the page, class - \"wsod_dataTable wsod_dataTableBigAlt\" has the data we need.\n",
        "# First get all the tables, then from each table extract the table-rows and finally,\n",
        "# from the rows, extract the table-data (stock names)\n",
        "# \n",
        "# Since we already know that there are 30 stocks on the page, in the order of 10 as \n",
        "# Most Actives, followed by Gainers as next 10 and lastly, 10 stocks in Losers, we can \n",
        "# split the stocks as pack of 10 stocks each\n",
        "def process_hot_stocks(hot_stocks_html):\n",
        "  stocks = []\n",
        "  tables = hot_stocks_html.find_all(\"table\", {\"class\": \"wsod_dataTable wsod_dataTableBigAlt\"})\n",
        "  for table in tables:\n",
        "    table_rows = table.find_all(\"tr\")\n",
        "    for table_row in table_rows:\n",
        "      table_data = table_row.find(\"td\")\n",
        "      if table_data:\n",
        "        stocks.append(table_data.text)\n",
        "\n",
        "  hot_stocks_dict = {}\n",
        "  for i in range(3):\n",
        "    stocks_classifier = hot_stocks_html.find_all(\"h3\")[i].text\n",
        "    boundary_left, boundary_right = i*10, (i+1)*10\n",
        "    hot_stocks_dict[stocks_classifier] = set(stocks[boundary_left:boundary_right])\n",
        "  \n",
        "  return hot_stocks_dict\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7B17s7kqtegM"
      },
      "source": [
        "# Reference: https://www.digitalocean.com/community/tutorials/how-to-work-with-web-data-using-requests-and-beautiful-soup-with-python-3\n",
        "# This function sends a get request to the URL -- \"https://money.cnn.com/data/hotstocks/\" and \n",
        "# parses the page using BeautifulSoup and calls process_hot_stocks() function to make 3 lists \n",
        "# of 10 stocks each. \n",
        "def fetch_hotstocks():\n",
        "  hot_stocks_url = \"https://money.cnn.com/data/hotstocks/\"\n",
        "  page = requests.get(hot_stocks_url)\n",
        "  parsed_page = BeautifulSoup(page.text, 'lxml')\n",
        "\n",
        "  hot_stocks_html = parsed_page.find(\"div\", {\"id\": \"wsod_hotStocks\"})\n",
        "  hot_stocks_dict = process_hot_stocks(hot_stocks_html)\n",
        "\n",
        "  return hot_stocks_dict"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATNwzFyRaoww"
      },
      "source": [
        "# This functions simply prints the data fetched from the URL -- \"https://money.cnn.com/data/hotstocks/\" \n",
        "# under the banner of which they were originally categorised\n",
        "def print_hot_stocks(hot_stocks_dict):\n",
        "  print('''This is a program to scrape data from the https://money.cnn.com/data/hotstocks/  for a class project.  \n",
        "  \n",
        "Which stock are you interested in: \n",
        "''')\n",
        "  for stocks_classifier, stocks in hot_stocks_dict.items():\n",
        "    print(f\"{stocks_classifier}:\")\n",
        "    for stock in stocks:\n",
        "      print(stock)\n",
        "    \n",
        "    print(\"\\n\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0Hzg3HMZVap"
      },
      "source": [
        "# This function helps parse the span tag from the page to extract the 4 values we \n",
        "# are interested in about the stock.\n",
        "def parse_values_from_page(parsed_page):\n",
        "  # From the website: https://finance.yahoo.com/quote/, it is apparent that the attribute\n",
        "  # \"data-reactid\" can be used to uniquely identify the values we are interested in.\n",
        "  # Attribute \"data-reactid\" values:\n",
        "  # Open -- 103\n",
        "  # Prev Close -- 98\n",
        "  # Volume --  126\n",
        "  # Market Cap -- 139\n",
        "  span_ids = [\"103\",\"98\",\"126\", \"139\"]\n",
        "\n",
        "  values = []\n",
        "  for span_id in span_ids:\n",
        "    if not parsed_page.find(\"span\", {\"data-reactid\": span_id}):\n",
        "      print(parsed_page)\n",
        "    # print(span_id, parsed_page.find(\"span\", {\"data-reactid\": span_id}))\n",
        "    values.append(parsed_page.find(\"span\", {\"data-reactid\": span_id}).text)\n",
        "\n",
        "  return values"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WXtIhGttpz0"
      },
      "source": [
        "# For each stock, this functions cooks the URL and gets information about the stock\n",
        "# under consideration. It then parses the page using BeautifulSoup and calls the\n",
        "# parse_values_from_page() function to extract the values we are interested in.\n",
        "def get_stocks_info(stocks):\n",
        "  stocks_dict = {}\n",
        "  print(\"Stocks in get_stocks_info():\", stocks)\n",
        "  for stock in stocks:\n",
        "    ticker_symbol = stock.split()[0]\n",
        "    stock_url = f\"https://finance.yahoo.com/quote/{ticker_symbol}\"\n",
        "\n",
        "    page = requests.get(stock_url)\n",
        "    parsed_page = BeautifulSoup(page.text, 'lxml')\n",
        "    stocks_dict[stock] = parse_values_from_page(parsed_page)\n",
        "\n",
        "  return stocks_dict"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Q55qeHyemNz"
      },
      "source": [
        "# As the name suggests, this function uses the two dictionary to construct the values\n",
        "# array to write to CSV in the order specified in the description of the project\n",
        "def write_stocks_to_csv(classifier_dict, stocks_dict):\n",
        "  with open('stocks.csv', 'w') as csv_file:\n",
        "    write = csv.writer(csv_file)\n",
        "\n",
        "    for stock, values in stocks_dict.items():\n",
        "      classifier = classifier_dict[stock]\n",
        "      ticker_symbol, company_name = stock.split(\" \", 1)\n",
        "      row = [classifier, ticker_symbol, company_name] + values\n",
        "      write.writerow(row)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5vbdMnwtfyE"
      },
      "source": [
        "# This fuctions prints the information about the stock that the user is interested in.\n",
        "# It first extracts the values from the stocks_dict (last four) and the name, and then \n",
        "# prints it out one-by-one.\n",
        "def print_stock_info(ticker_symbol, stocks_dict):\n",
        "  found = False\n",
        "  values = []\n",
        "  for stock, info in stocks_dict.items():\n",
        "    stock_symbol = stock.split(\" \", 1)[0]\n",
        "    if stock_symbol == ticker_symbol:\n",
        "      values.append(stock)\n",
        "      values.extend(info)\n",
        "      found = True\n",
        "\n",
        "  if not found:\n",
        "    print(\"No such ticker-symbol noted while processing hot-stocks\")\n",
        "    return \n",
        "\n",
        "  print(f\"The data for {values[0]} is the following: \")\n",
        "  print(values[0])\n",
        "  print(\"OPEN:\", values[1])\n",
        "  print(\"PREV CLOSE:\", values[2])\n",
        "  print(\"VOLUME:\", values[3])\n",
        "  print(\"MARKET CAP:\", values[4])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08KJKsEmsih9"
      },
      "source": [
        "try:\n",
        "  # make dictionary of the hot-stocks under thier stock-type (Most Active, Gainers, Losers)\n",
        "  # for faster access\n",
        "  hot_stocks_dict = fetch_hotstocks()\n",
        "\n",
        "  # make dictionary of stock to stock-type for the use of writing to csv\n",
        "  classifier_dict = {}\n",
        "  for key, values in hot_stocks_dict.items():\n",
        "    for value in values:\n",
        "      classifier_dict[value] = key\n",
        "\n",
        "  # make a list of all stocks, to collectively get information about each stock\n",
        "  stocks = []\n",
        "  for values in hot_stocks_dict.values():\n",
        "    stocks.extend(values)\n",
        "  stocks_dict = get_stocks_info(stocks)\n",
        "\n",
        "  # using the data from the two dicitonary, make rows of values and write to csv file \n",
        "  write_stocks_to_csv(classifier_dict, stocks_dict)\n",
        "\n",
        "  # Print hot stocks information\n",
        "  print_hot_stocks(hot_stocks_dict)\n",
        "  \n",
        "  # finally prompt user to input ticker symbol for a stock and print information about \n",
        "  # the stock if it is present in the hot-stocks list.\n",
        "  ticker_symbol = input(\"User inputs:\").strip().upper()\n",
        "  print_stock_info(ticker_symbol, stocks_dict)\n",
        "\n",
        "except Exception as ex:\n",
        "  print(f\"Exception encountered while reading ticker symbol: {ex}\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}